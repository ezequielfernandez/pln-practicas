{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bdd3d1e5661649759bb30f42db755609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed64058acba64d0d9d3d44a5c4075aad",
              "IPY_MODEL_17fa91d8a6f0439b8fe4039115ac8e62",
              "IPY_MODEL_a354c610c2e94eab8205bf497603f01c"
            ],
            "layout": "IPY_MODEL_90ac58e06cb14db29386b744af261bf2"
          }
        },
        "ed64058acba64d0d9d3d44a5c4075aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b239c947cfc844ce821a0172cb18cbce",
            "placeholder": "​",
            "style": "IPY_MODEL_f6aa12db27c1474d9b26bcf8b9b5c5a5",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: "
          }
        },
        "17fa91d8a6f0439b8fe4039115ac8e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5006d1aa5e3b4d95a01539a08caf5adb",
            "max": 24144,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69fda5adcb824938aa465a1c65ec0a73",
            "value": 24144
          }
        },
        "a354c610c2e94eab8205bf497603f01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a6b79bde35c4a73bfdbd2d12390625e",
            "placeholder": "​",
            "style": "IPY_MODEL_43a402a9e7dd4ca5958686efc2d18951",
            "value": " 140k/? [00:00&lt;00:00, 4.91MB/s]"
          }
        },
        "90ac58e06cb14db29386b744af261bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b239c947cfc844ce821a0172cb18cbce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6aa12db27c1474d9b26bcf8b9b5c5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5006d1aa5e3b4d95a01539a08caf5adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69fda5adcb824938aa465a1c65ec0a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a6b79bde35c4a73bfdbd2d12390625e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a402a9e7dd4ca5958686efc2d18951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "pyd-j-QhnDKz"
      },
      "outputs": [],
      "source": [
        "# La última versión de spacy-stanza (>1.0) es compatible solo con spacy >=3.0\n",
        "# Nota: spacy 3.0 incorpora al pepiline nlp transformers\n",
        "!pip install -U spacy==3.1 --quiet\n",
        "!pip install -U spacy-stanza==1.0.0 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import string\n",
        "import random \n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "zNypoNpOrEnk"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "import spacy_stanza\n",
        "stanza.download(\"es\")\n",
        "nlp = spacy_stanza.load_pipeline(\"es\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460,
          "referenced_widgets": [
            "bdd3d1e5661649759bb30f42db755609",
            "ed64058acba64d0d9d3d44a5c4075aad",
            "17fa91d8a6f0439b8fe4039115ac8e62",
            "a354c610c2e94eab8205bf497603f01c",
            "90ac58e06cb14db29386b744af261bf2",
            "b239c947cfc844ce821a0172cb18cbce",
            "f6aa12db27c1474d9b26bcf8b9b5c5a5",
            "5006d1aa5e3b4d95a01539a08caf5adb",
            "69fda5adcb824938aa465a1c65ec0a73",
            "3a6b79bde35c4a73bfdbd2d12390625e",
            "43a402a9e7dd4ca5958686efc2d18951"
          ]
        },
        "id": "Y8AA2dLgrIpA",
        "outputId": "64a67362-1b04-4aac-9816-1fce6867a0cb"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdd3d1e5661649759bb30f42db755609"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloading default packages for language: es (Spanish)...\n",
            "INFO:stanza:File exists: /root/stanza_resources/es/default.zip.\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources.\n",
            "INFO:stanza:Loading these models for language: es (Spanish):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ancora  |\n",
            "| mwt       | ancora  |\n",
            "| pos       | ancora  |\n",
            "| lemma     | ancora  |\n",
            "| depparse  | ancora  |\n",
            "| ner       | conll02 |\n",
            "=======================\n",
            "\n",
            "INFO:stanza:Use device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: mwt\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: lemma\n",
            "INFO:stanza:Loading: depparse\n",
            "INFO:stanza:Loading: ner\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocesamiento de datos"
      ],
      "metadata": {
        "id": "9TbfKSaMrRGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Quitar acentos y caracteres especiales\n",
        "* Quitar números\n",
        "* Quitar símbolos de puntuación"
      ],
      "metadata": {
        "id": "DPptFU8NrWqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def preprocess_clean_text(text):    \n",
        "    # sacar tildes de las palabras:\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    # quitar caracteres especiales\n",
        "    pattern = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' # Se eliminar cualquier caracter distinto de los del regex\n",
        "    text = re.sub(pattern, '', text)\n",
        "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]'\n",
        "    # quitar números\n",
        "    text = re.sub(pattern, '', text)\n",
        "    # quitar caracteres de puntuación\n",
        "    text = ''.join([c for c in text if c not in string.punctuation])\n",
        "    return text"
      ],
      "metadata": {
        "id": "Z58VTzGLrTWR"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"texto antes del preprocesamiento en el que quitamos acentos, números y caracteres especiales\"\n",
        "\n",
        "print(\"preprocess text: \", preprocess_clean_text(text.lower()))\n",
        "\n",
        "tokens = nlp(preprocess_clean_text(text.lower()))\n",
        "print(\"tokens:\", tokens)\n",
        "print(\"Lematización de cada token:\")\n",
        "for token in tokens:\n",
        "    print([token, token.lemma_])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ifKdNvzrtOm",
        "outputId": "ad6ce8bb-ce16-4554-d1d5-b18810157b98"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocess text:  texto antes del preprocesamiento en el que quitamos acentos numeros y caracteres especiales\n",
            "tokens: texto antes de el preprocesamiento en el que quitamos acentos numeros y caracteres especiales \n",
            "Lematización de cada token:\n",
            "[texto, 'texto']\n",
            "[antes, 'antes']\n",
            "[de, 'de']\n",
            "[el, 'el']\n",
            "[preprocesamiento, 'preprocesamiento']\n",
            "[en, 'en']\n",
            "[el, 'el']\n",
            "[que, 'que']\n",
            "[quitamos, 'quitar']\n",
            "[acentos, 'acento']\n",
            "[numeros, 'numero']\n",
            "[y, 'y']\n",
            "[caracteres, 'carácter']\n",
            "[especiales, 'especial']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-96-47f3048004fb>:5: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
            "  tokens = nlp(preprocess_clean_text(text.lower()))\n",
            "<ipython-input-96-47f3048004fb>:5: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['texto', 'antes', 'de', 'el', 'preprocesamiento', 'en', 'el', 'que', 'quitamos', 'acentos', 'numeros', 'y', 'caracteres', 'especiales']\n",
            "Entities: []\n",
            "  tokens = nlp(preprocess_clean_text(text.lower()))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {\"intents\": [\n",
        "             {\"tag\": \"bienvenida\",\n",
        "              \"patterns\": [\"Hola\", \"Buenas\", \"Buenos días\", \"Buenas tardes\", \"Buenas noches\", \"¿Cómo estás?\", \"¿Qué tal?\"],\n",
        "              \"responses\": [\"Hola!\", \"Hola, ¿Cómo estás?\"],\n",
        "             },\n",
        "             {\"tag\": \"nombre\",\n",
        "              \"patterns\": [\"¿Cúal es tu nombre?\", \"¿Quién sos?\", \"¿Como te llamas?\", \"¿Podes presentarte?\", \"Presentese por favor\", \"¿Como te puedo llamar?\"],\n",
        "              \"responses\": [\"Mi nombre es TuBot\", \"Yo soy TuBot\", \"Soy TuBot y estoy para ayudarte\"]\n",
        "             },\n",
        "            {\"tag\": \"contacto\",\n",
        "              \"patterns\": [\"contacto\", \"número de contacto\", \"número de teléfono\", \"número de whatsapp\", \"whatsapp\", \"¿te puedo llamar?\", \"Quiero llamar a la empresa\", \"Me gustaria contactarme por otro medio\", \"Me gustaría hablar con un empleado\"],\n",
        "              \"responses\": [\"Podes contactarnos al siguiente <numero>\", \"Escríbenos al whatsapp <numero>\"]\n",
        "             },\n",
        "            {\"tag\": \"envios\",\n",
        "              \"patterns\": [\"¿Realizan envios?\", \"¿Cómo me llega el paquete?\", \"¿Hacen envíos a domicilio?\", \"¿Hacen envíos a sucursales?\"],\n",
        "              \"responses\": [\"Tenemos diferentes formas de envios según la zona, te recomiendo entrar a este <link>\"]\n",
        "             },\n",
        "            {\"tag\": \"mis_envios\",\n",
        "              \"patterns\": [\"Estado de mi envio\", \"Cuando llega mi paquete\", \"Por que mi paquete todavia no llego\", \"Quiero que llegue mi paquete\", \"Necesito que llegue mi producto\", \"Aún no llego mi compra\", \"Mi compra deberia haber llegado y no llego\", \"LLego mi producto pero no estaba en mi casa, ¿volveran a pasar?\", \"No estaba en mi domicilio, ¿vuelven a pasar?\", \"Aún no se despacho el producto\", \"¿Cuando despacharan mi compra?\"],\n",
        "              \"responses\": [\"Podes ver los detalles de tu envio en el siguiente link <link> allí podrás iniciar un reclamo si el envío está demorado\"]\n",
        "             },\n",
        "            {\"tag\": \"compra\",\n",
        "              \"patterns\": [\"compra\", \"Tengo un problema con mi compra\", \"Quiero ver los detalles de mi compra\", \"Quiero saber el estado de mi compra\"],\n",
        "              \"responses\": [\"En el siguiente link podrás encontrar tus compras y los detalles de las mismas <link>\"]\n",
        "             },\n",
        "            {\"tag\": \"pagos\",\n",
        "              \"patterns\": [\"medios de pago\", \"tarjeta de crédito\", \"tarjetas\", \"cuotas\"],\n",
        "              \"responses\": [\"En el siguiente link podrás encontrar los beneficios y formas de pago vigentes\"]\n",
        "             },\n",
        "            {\"tag\": \"stock\",\n",
        "              \"patterns\": [\"Esto está disponible\", \"¿Tenes stock?\", \"¿Hay stock hoy?\", \"¿Como se si hay stock?\", \"¿El producto se encuentra disponible?\"],\n",
        "              \"responses\": [\"Si el producto se encuentra publicado, hay stock del mismo\"]\n",
        "             },\n",
        "            {\"tag\": \"opinar\",\n",
        "              \"patterns\": [\"opinar\", \"Quiero calificar un producto\", \"Como opino sobre un producto\"],\n",
        "              \"responses\": [\"En el siguiente link podrás encontrar tus compras y calificar los productos <link>\"]\n",
        "             },\n",
        "            {\"tag\": \"agradecimientos\",\n",
        "              \"patterns\": [ \"Muchas gracias\", \"Gracias\", \"Gracias por tu ayuda\", \"Te agradezco\"],\n",
        "              \"responses\": [\"¡Por nada!, cualquier otra consulta podes escribirme\"]\n",
        "             },\n",
        "             {\"tag\": \"despedida\",\n",
        "              \"patterns\": [ \"Chau\", \"Hasta luego!\", \"Saludos\", \"Nos vemos\", \"Adios\"],\n",
        "              \"responses\": [\"Hasta luego!\", \"Hablamos luego!\"]\n",
        "             }\n",
        "]}"
      ],
      "metadata": {
        "id": "dGw09SrkswX3"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk_stop_words = set(stopwords.words(\"spanish\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVskRToF43yf",
        "outputId": "47758ccf-022e-4ac1-d029-c2a8d4ba3daa"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos que necesitaremos, las palabras o vocabulario\n",
        "words = []\n",
        "classes = []\n",
        "doc_X = []\n",
        "doc_y = []\n",
        "# Por cada intención (intents) tomaremos los patrones que la caracterízan a esa intención y la transformaremos a tokens para almacenar en doc_X\n",
        "# El tag de cada intención se almacena como doc_Y (la clase a predecir)\n",
        "# En `words` vamos a guardar el vocabulario\n",
        "# En `class` las posibles clases o tags\n",
        "\n",
        "for intent in dataset[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        # trasformar el patron a tokens\n",
        "        tokens = nlp(preprocess_clean_text(pattern.lower()))\n",
        "        # lematizar los tokens\n",
        "        document = []\n",
        "        for token in tokens:\n",
        "          # Filtramos las stopwords\n",
        "          if (token.lemma_ not in nltk_stop_words):            \n",
        "            words.append(token.lemma_)\n",
        "        \n",
        "        doc_X.append(pattern)\n",
        "        doc_y.append(intent[\"tag\"])\n",
        "    \n",
        "    # Agregar el tag a las clases\n",
        "    if intent[\"tag\"] not in classes:\n",
        "        classes.append(intent[\"tag\"])\n",
        "\n",
        "# Elminar duplicados con \"set\" y ordenar el vocubulario y las clases por orden alfabético\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))"
      ],
      "metadata": {
        "id": "7DfE19RpvsMS"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"words:\", len(words))\n",
        "print(\"classes:\", classes)\n",
        "print(\"doc_X:\", doc_X)\n",
        "print(\"doc_y:\", doc_y)\n",
        "# Tamaño del vocabulario\n",
        "print(\"Vocabulario:\", len(words))\n",
        "# Cantidad de tags\n",
        "print(\"Tags:\", len(classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHuRXw6hvwNz",
        "outputId": "e73a08f5-f5e0-4e3d-c344-ea3cc8b42dcf"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words: 67\n",
            "classes: ['agradecimientos', 'bienvenida', 'compra', 'contacto', 'despedida', 'envios', 'mis_envios', 'nombre', 'opinar', 'pagos', 'stock']\n",
            "doc_X: ['Hola', 'Buenas', 'Buenos días', 'Buenas tardes', 'Buenas noches', '¿Cómo estás?', '¿Qué tal?', '¿Cúal es tu nombre?', '¿Quién sos?', '¿Como te llamas?', '¿Podes presentarte?', 'Presentese por favor', '¿Como te puedo llamar?', 'contacto', 'número de contacto', 'número de teléfono', 'número de whatsapp', 'whatsapp', '¿te puedo llamar?', 'Quiero llamar a la empresa', 'Me gustaria contactarme por otro medio', 'Me gustaría hablar con un empleado', '¿Realizan envios?', '¿Cómo me llega el paquete?', '¿Hacen envíos a domicilio?', '¿Hacen envíos a sucursales?', 'Estado de mi envio', 'Cuando llega mi paquete', 'Por que mi paquete todavia no llego', 'Quiero que llegue mi paquete', 'Necesito que llegue mi producto', 'Aún no llego mi compra', 'Mi compra deberia haber llegado y no llego', 'LLego mi producto pero no estaba en mi casa, ¿volveran a pasar?', 'No estaba en mi domicilio, ¿vuelven a pasar?', 'Aún no se despacho el producto', '¿Cuando despacharan mi compra?', 'compra', 'Tengo un problema con mi compra', 'Quiero ver los detalles de mi compra', 'Quiero saber el estado de mi compra', 'medios de pago', 'tarjeta de crédito', 'tarjetas', 'cuotas', 'Esto está disponible', '¿Tenes stock?', '¿Hay stock hoy?', '¿Como se si hay stock?', '¿El producto se encuentra disponible?', 'opinar', 'Quiero calificar un producto', 'Como opino sobre un producto', 'Muchas gracias', 'Gracias', 'Gracias por tu ayuda', 'Te agradezco', 'Chau', 'Hasta luego!', 'Saludos', 'Nos vemos', 'Adios']\n",
            "doc_y: ['bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'nombre', 'nombre', 'nombre', 'nombre', 'nombre', 'nombre', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'envios', 'envios', 'envios', 'envios', 'mis_envios', 'mis_envios', 'mis_envios', 'mis_envios', 'mis_envios', 'mis_envios', 'mis_envios', 'mis_envios', 'mis_envios', 'mis_envios', 'mis_envios', 'compra', 'compra', 'compra', 'compra', 'pagos', 'pagos', 'pagos', 'pagos', 'stock', 'stock', 'stock', 'stock', 'stock', 'opinar', 'opinar', 'opinar', 'agradecimientos', 'agradecimientos', 'agradecimientos', 'agradecimientos', 'despedida', 'despedida', 'despedida', 'despedida', 'despedida']\n",
            "Vocabulario: 67\n",
            "Tags: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformar doc_X en bag of words por oneHotEncoding\n",
        "# Transformar doc_Y en un vector de clases multicategórico con oneHotEncoding\n",
        "\n",
        "training = []\n",
        "out_empty = [0] * len(classes)\n",
        "\n",
        "for idx, doc in enumerate(doc_X):\n",
        "    # Transformar el input en tokens y lematizar, filtrando stop words\n",
        "    text = []\n",
        "    tokens = nlp(preprocess_clean_text(doc.lower()))\n",
        "    for token in tokens:\n",
        "      if (token.lemma_ not in nltk_stop_words):\n",
        "        text.append(token.lemma_)\n",
        "\n",
        "    # Transformar los tokens en \"Bag of words\" (arrays de 1 y 0)\n",
        "    bow = []\n",
        "    for word in words:\n",
        "        bow.append(1) if word in text else bow.append(0)\n",
        "    \n",
        "    # Crear el array de salida (class output) correspondiente\n",
        "    output_row = list(out_empty)\n",
        "    output_row[classes.index(doc_y[idx])] = 1\n",
        "\n",
        "    print(\"X:\", bow, \"y:\", output_row)\n",
        "    training.append([bow, output_row])\n",
        "\n",
        "# Mezclar los datos\n",
        "random.shuffle(training)\n",
        "training = np.array(training, dtype=object)\n",
        "# Dividir en datos de entrada y salida\n",
        "train_X = np.array(list(training[:, 0]))\n",
        "train_y = np.array(list(training[:, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzZRMZlOv2or",
        "outputId": "f2cc20c1-d786-4dce-d50a-a40efb4632e0"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] y: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] y: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "X: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que se reduce la dimensionalidad dado que eliminamos stop words"
      ],
      "metadata": {
        "id": "167vEtLM_-v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape de entrada y salida\n",
        "input_shape = (train_X.shape[1],)\n",
        "output_shape = train_y.shape[1]\n",
        "print(\"input:\", input_shape, \"output:\", output_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avcp2A5bv7_6",
        "outputId": "d92beaab-f76f-4bc1-bd2a-2129bce7f2e2"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: (67,) output: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo DNN\n",
        "# - Modelo secuencial\n",
        "# - Con regularización\n",
        "# - softmax y optimizador Adam\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(output_shape, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH1hQuiiv9qh",
        "outputId": "093a20bb-8a11-4012-bb87-7bf11c042e7c"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 128)               8704      \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 11)                715       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,675\n",
            "Trainable params: 17,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x=train_X, y=train_y, epochs=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpjkoT02wApA",
        "outputId": "6e77802f-489f-4351-93fd-09ed0362d83f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "2/2 [==============================] - 2s 10ms/step - loss: 2.4671 - accuracy: 0.0645\n",
            "Epoch 2/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3929 - accuracy: 0.0484\n",
            "Epoch 3/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.3926 - accuracy: 0.1290\n",
            "Epoch 4/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.3943 - accuracy: 0.0806\n",
            "Epoch 5/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3355 - accuracy: 0.1452\n",
            "Epoch 6/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3433 - accuracy: 0.1774\n",
            "Epoch 7/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.3751 - accuracy: 0.1290\n",
            "Epoch 8/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.3329 - accuracy: 0.1452\n",
            "Epoch 9/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2987 - accuracy: 0.2097\n",
            "Epoch 10/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3150 - accuracy: 0.1935\n",
            "Epoch 11/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.3193 - accuracy: 0.2419\n",
            "Epoch 12/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.2863 - accuracy: 0.2258\n",
            "Epoch 13/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.2745 - accuracy: 0.2419\n",
            "Epoch 14/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.2138 - accuracy: 0.3065\n",
            "Epoch 15/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.2458 - accuracy: 0.1935\n",
            "Epoch 16/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.1886 - accuracy: 0.2742\n",
            "Epoch 17/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2188 - accuracy: 0.3065\n",
            "Epoch 18/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.1782 - accuracy: 0.2581\n",
            "Epoch 19/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2207 - accuracy: 0.2903\n",
            "Epoch 20/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.1496 - accuracy: 0.3387\n",
            "Epoch 21/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.1217 - accuracy: 0.3065\n",
            "Epoch 22/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.1418 - accuracy: 0.3548\n",
            "Epoch 23/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.1097 - accuracy: 0.3710\n",
            "Epoch 24/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0996 - accuracy: 0.3226\n",
            "Epoch 25/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0812 - accuracy: 0.3871\n",
            "Epoch 26/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0484 - accuracy: 0.2742\n",
            "Epoch 27/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0590 - accuracy: 0.2742\n",
            "Epoch 28/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0404 - accuracy: 0.3226\n",
            "Epoch 29/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9599 - accuracy: 0.4355\n",
            "Epoch 30/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9548 - accuracy: 0.3387\n",
            "Epoch 31/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9226 - accuracy: 0.4194\n",
            "Epoch 32/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9261 - accuracy: 0.3871\n",
            "Epoch 33/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9013 - accuracy: 0.3871\n",
            "Epoch 34/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9190 - accuracy: 0.3710\n",
            "Epoch 35/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9030 - accuracy: 0.3871\n",
            "Epoch 36/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8413 - accuracy: 0.3871\n",
            "Epoch 37/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8965 - accuracy: 0.4032\n",
            "Epoch 38/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8441 - accuracy: 0.3710\n",
            "Epoch 39/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7911 - accuracy: 0.4516\n",
            "Epoch 40/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7635 - accuracy: 0.4839\n",
            "Epoch 41/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7229 - accuracy: 0.4677\n",
            "Epoch 42/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6719 - accuracy: 0.5484\n",
            "Epoch 43/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.6985 - accuracy: 0.5000\n",
            "Epoch 44/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6233 - accuracy: 0.5484\n",
            "Epoch 45/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6940 - accuracy: 0.3871\n",
            "Epoch 46/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6267 - accuracy: 0.5323\n",
            "Epoch 47/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5969 - accuracy: 0.6613\n",
            "Epoch 48/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6008 - accuracy: 0.5484\n",
            "Epoch 49/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5255 - accuracy: 0.5000\n",
            "Epoch 50/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5958 - accuracy: 0.4677\n",
            "Epoch 51/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5287 - accuracy: 0.5484\n",
            "Epoch 52/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.5315 - accuracy: 0.5323\n",
            "Epoch 53/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5132 - accuracy: 0.6774\n",
            "Epoch 54/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4011 - accuracy: 0.5968\n",
            "Epoch 55/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3455 - accuracy: 0.6613\n",
            "Epoch 56/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4014 - accuracy: 0.6129\n",
            "Epoch 57/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4017 - accuracy: 0.5484\n",
            "Epoch 58/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3631 - accuracy: 0.6774\n",
            "Epoch 59/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3536 - accuracy: 0.5323\n",
            "Epoch 60/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3476 - accuracy: 0.6613\n",
            "Epoch 61/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.3408 - accuracy: 0.5968\n",
            "Epoch 62/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1937 - accuracy: 0.7097\n",
            "Epoch 63/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3773 - accuracy: 0.6774\n",
            "Epoch 64/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2596 - accuracy: 0.7097\n",
            "Epoch 65/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0868 - accuracy: 0.6935\n",
            "Epoch 66/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1351 - accuracy: 0.6935\n",
            "Epoch 67/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1191 - accuracy: 0.6129\n",
            "Epoch 68/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0574 - accuracy: 0.7581\n",
            "Epoch 69/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0859 - accuracy: 0.7742\n",
            "Epoch 70/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1256 - accuracy: 0.7903\n",
            "Epoch 71/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1336 - accuracy: 0.7581\n",
            "Epoch 72/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0321 - accuracy: 0.7419\n",
            "Epoch 73/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1144 - accuracy: 0.7581\n",
            "Epoch 74/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9487 - accuracy: 0.7903\n",
            "Epoch 75/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9737 - accuracy: 0.7903\n",
            "Epoch 76/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9900 - accuracy: 0.7419\n",
            "Epoch 77/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9062 - accuracy: 0.8065\n",
            "Epoch 78/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8639 - accuracy: 0.8226\n",
            "Epoch 79/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9018 - accuracy: 0.7903\n",
            "Epoch 80/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9305 - accuracy: 0.7903\n",
            "Epoch 81/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9178 - accuracy: 0.7903\n",
            "Epoch 82/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7483 - accuracy: 0.8710\n",
            "Epoch 83/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9253 - accuracy: 0.8065\n",
            "Epoch 84/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7602 - accuracy: 0.8548\n",
            "Epoch 85/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7636 - accuracy: 0.8710\n",
            "Epoch 86/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8300 - accuracy: 0.8710\n",
            "Epoch 87/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7823 - accuracy: 0.7903\n",
            "Epoch 88/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8185 - accuracy: 0.8387\n",
            "Epoch 89/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7345 - accuracy: 0.8548\n",
            "Epoch 90/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7661 - accuracy: 0.8226\n",
            "Epoch 91/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7010 - accuracy: 0.8710\n",
            "Epoch 92/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7689 - accuracy: 0.7903\n",
            "Epoch 93/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7618 - accuracy: 0.8548\n",
            "Epoch 94/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6053 - accuracy: 0.8387\n",
            "Epoch 95/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7082 - accuracy: 0.8226\n",
            "Epoch 96/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6698 - accuracy: 0.8226\n",
            "Epoch 97/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6946 - accuracy: 0.8871\n",
            "Epoch 98/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5682 - accuracy: 0.9355\n",
            "Epoch 99/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6294 - accuracy: 0.8548\n",
            "Epoch 100/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.8387\n",
            "Epoch 101/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6870 - accuracy: 0.8065\n",
            "Epoch 102/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5983 - accuracy: 0.9194\n",
            "Epoch 103/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5390 - accuracy: 0.9194\n",
            "Epoch 104/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5401 - accuracy: 0.8871\n",
            "Epoch 105/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6218 - accuracy: 0.9032\n",
            "Epoch 106/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6222 - accuracy: 0.8548\n",
            "Epoch 107/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6781 - accuracy: 0.8226\n",
            "Epoch 108/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4921 - accuracy: 0.9194\n",
            "Epoch 109/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5174 - accuracy: 0.9032\n",
            "Epoch 110/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6115 - accuracy: 0.8387\n",
            "Epoch 111/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4938 - accuracy: 0.9355\n",
            "Epoch 112/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5157 - accuracy: 0.8710\n",
            "Epoch 113/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5706 - accuracy: 0.9032\n",
            "Epoch 114/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5176 - accuracy: 0.8710\n",
            "Epoch 115/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4499 - accuracy: 0.9032\n",
            "Epoch 116/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4637 - accuracy: 0.9032\n",
            "Epoch 117/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5428 - accuracy: 0.8710\n",
            "Epoch 118/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4875 - accuracy: 0.9032\n",
            "Epoch 119/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.8871\n",
            "Epoch 120/300\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4551 - accuracy: 0.9032\n",
            "Epoch 121/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4241 - accuracy: 0.9032\n",
            "Epoch 122/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5108 - accuracy: 0.8871\n",
            "Epoch 123/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4507 - accuracy: 0.9194\n",
            "Epoch 124/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4430 - accuracy: 0.8871\n",
            "Epoch 125/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4123 - accuracy: 0.9032\n",
            "Epoch 126/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4037 - accuracy: 0.8871\n",
            "Epoch 127/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4667 - accuracy: 0.8710\n",
            "Epoch 128/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3348 - accuracy: 0.9839\n",
            "Epoch 129/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4881 - accuracy: 0.8710\n",
            "Epoch 130/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3196 - accuracy: 0.9677\n",
            "Epoch 131/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3587 - accuracy: 0.9355\n",
            "Epoch 132/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2719 - accuracy: 0.9355\n",
            "Epoch 133/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2805 - accuracy: 0.9516\n",
            "Epoch 134/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3244 - accuracy: 0.9355\n",
            "Epoch 135/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4206 - accuracy: 0.8871\n",
            "Epoch 136/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3500 - accuracy: 0.9194\n",
            "Epoch 137/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4450 - accuracy: 0.9032\n",
            "Epoch 138/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3965 - accuracy: 0.9032\n",
            "Epoch 139/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4380 - accuracy: 0.8387\n",
            "Epoch 140/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3327 - accuracy: 0.9355\n",
            "Epoch 141/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3694 - accuracy: 0.9194\n",
            "Epoch 142/300\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3158 - accuracy: 0.9355\n",
            "Epoch 143/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3691 - accuracy: 0.8871\n",
            "Epoch 144/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3908 - accuracy: 0.8871\n",
            "Epoch 145/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4314 - accuracy: 0.8871\n",
            "Epoch 146/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3246 - accuracy: 0.9355\n",
            "Epoch 147/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 0.9194\n",
            "Epoch 148/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3318 - accuracy: 0.8871\n",
            "Epoch 149/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3164 - accuracy: 0.9677\n",
            "Epoch 150/300\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2978 - accuracy: 0.9516\n",
            "Epoch 151/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3489 - accuracy: 0.9355\n",
            "Epoch 152/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2501 - accuracy: 0.9516\n",
            "Epoch 153/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3091 - accuracy: 0.9032\n",
            "Epoch 154/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3944 - accuracy: 0.8871\n",
            "Epoch 155/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3162 - accuracy: 0.8871\n",
            "Epoch 156/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2735 - accuracy: 0.9194\n",
            "Epoch 157/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2878 - accuracy: 0.9355\n",
            "Epoch 158/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2973 - accuracy: 0.9355\n",
            "Epoch 159/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3385 - accuracy: 0.8871\n",
            "Epoch 160/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3336 - accuracy: 0.9194\n",
            "Epoch 161/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3225 - accuracy: 0.9516\n",
            "Epoch 162/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2153 - accuracy: 0.9677\n",
            "Epoch 163/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2934 - accuracy: 0.9355\n",
            "Epoch 164/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2229 - accuracy: 0.9355\n",
            "Epoch 165/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2110 - accuracy: 0.9516\n",
            "Epoch 166/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.9194\n",
            "Epoch 167/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3063 - accuracy: 0.9355\n",
            "Epoch 168/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2241 - accuracy: 0.9516\n",
            "Epoch 169/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2188 - accuracy: 0.9516\n",
            "Epoch 170/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2047 - accuracy: 0.9677\n",
            "Epoch 171/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3031 - accuracy: 0.9032\n",
            "Epoch 172/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2381 - accuracy: 0.9355\n",
            "Epoch 173/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2248 - accuracy: 0.9516\n",
            "Epoch 174/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1940 - accuracy: 0.9677\n",
            "Epoch 175/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2607 - accuracy: 0.9516\n",
            "Epoch 176/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2821 - accuracy: 0.9032\n",
            "Epoch 177/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3276 - accuracy: 0.9194\n",
            "Epoch 178/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2460 - accuracy: 0.9516\n",
            "Epoch 179/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1857 - accuracy: 0.9677\n",
            "Epoch 180/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2140 - accuracy: 0.9516\n",
            "Epoch 181/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3443 - accuracy: 0.9032\n",
            "Epoch 182/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2277 - accuracy: 0.9839\n",
            "Epoch 183/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2709 - accuracy: 0.9194\n",
            "Epoch 184/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.9355\n",
            "Epoch 185/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3041 - accuracy: 0.8871\n",
            "Epoch 186/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2107 - accuracy: 0.9677\n",
            "Epoch 187/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3278 - accuracy: 0.8710\n",
            "Epoch 188/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2116 - accuracy: 0.9677\n",
            "Epoch 189/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2874 - accuracy: 0.9516\n",
            "Epoch 190/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2002 - accuracy: 0.9677\n",
            "Epoch 191/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1993 - accuracy: 0.9677\n",
            "Epoch 192/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2043 - accuracy: 0.9516\n",
            "Epoch 193/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2412 - accuracy: 0.9355\n",
            "Epoch 194/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2182 - accuracy: 0.9355\n",
            "Epoch 195/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2068 - accuracy: 0.9516\n",
            "Epoch 196/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1527 - accuracy: 0.9194\n",
            "Epoch 197/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1332 - accuracy: 0.9839\n",
            "Epoch 198/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2077 - accuracy: 0.9677\n",
            "Epoch 199/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1923 - accuracy: 0.9516\n",
            "Epoch 200/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2428 - accuracy: 0.9194\n",
            "Epoch 201/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1641 - accuracy: 0.9677\n",
            "Epoch 202/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2146 - accuracy: 0.9355\n",
            "Epoch 203/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1645 - accuracy: 0.9516\n",
            "Epoch 204/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1966 - accuracy: 0.9355\n",
            "Epoch 205/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1661 - accuracy: 0.9677\n",
            "Epoch 206/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1708 - accuracy: 0.9677\n",
            "Epoch 207/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2120 - accuracy: 0.9516\n",
            "Epoch 208/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2041 - accuracy: 0.9516\n",
            "Epoch 209/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2385 - accuracy: 0.9032\n",
            "Epoch 210/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1867 - accuracy: 0.9516\n",
            "Epoch 211/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2240 - accuracy: 0.8871\n",
            "Epoch 212/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2204 - accuracy: 0.9032\n",
            "Epoch 213/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1528 - accuracy: 0.9516\n",
            "Epoch 214/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2254 - accuracy: 0.9355\n",
            "Epoch 215/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1365 - accuracy: 0.9355\n",
            "Epoch 216/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1465 - accuracy: 0.9839\n",
            "Epoch 217/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1677 - accuracy: 0.9516\n",
            "Epoch 218/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1684 - accuracy: 0.9516\n",
            "Epoch 219/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1375 - accuracy: 0.9677\n",
            "Epoch 220/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2389 - accuracy: 0.9355\n",
            "Epoch 221/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1475 - accuracy: 0.9677\n",
            "Epoch 222/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1779 - accuracy: 0.9516\n",
            "Epoch 223/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2750 - accuracy: 0.9355\n",
            "Epoch 224/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1791 - accuracy: 0.9516\n",
            "Epoch 225/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2075 - accuracy: 0.9516\n",
            "Epoch 226/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2028 - accuracy: 0.9355\n",
            "Epoch 227/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2275 - accuracy: 0.9194\n",
            "Epoch 228/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1845 - accuracy: 0.9516\n",
            "Epoch 229/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.9677\n",
            "Epoch 230/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2258 - accuracy: 0.9516\n",
            "Epoch 231/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1552 - accuracy: 0.9355\n",
            "Epoch 232/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2799 - accuracy: 0.8710\n",
            "Epoch 233/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1927 - accuracy: 0.9516\n",
            "Epoch 234/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1811 - accuracy: 0.9516\n",
            "Epoch 235/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1584 - accuracy: 0.9677\n",
            "Epoch 236/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1801 - accuracy: 0.9516\n",
            "Epoch 237/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1334 - accuracy: 0.9516\n",
            "Epoch 238/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1874 - accuracy: 0.9516\n",
            "Epoch 239/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1163 - accuracy: 0.9677\n",
            "Epoch 240/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1383 - accuracy: 0.9516\n",
            "Epoch 241/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1506 - accuracy: 0.9839\n",
            "Epoch 242/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1550 - accuracy: 0.9516\n",
            "Epoch 243/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2673 - accuracy: 0.9194\n",
            "Epoch 244/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1254 - accuracy: 0.9677\n",
            "Epoch 245/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1700 - accuracy: 0.9355\n",
            "Epoch 246/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2185 - accuracy: 0.9194\n",
            "Epoch 247/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1696 - accuracy: 0.9516\n",
            "Epoch 248/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1777 - accuracy: 0.9516\n",
            "Epoch 249/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1348 - accuracy: 0.9677\n",
            "Epoch 250/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1709 - accuracy: 0.9516\n",
            "Epoch 251/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1894 - accuracy: 0.9355\n",
            "Epoch 252/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2091 - accuracy: 0.9355\n",
            "Epoch 253/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1226 - accuracy: 0.9677\n",
            "Epoch 254/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1382 - accuracy: 0.9839\n",
            "Epoch 255/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1814 - accuracy: 0.9032\n",
            "Epoch 256/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1487 - accuracy: 0.9677\n",
            "Epoch 257/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1477 - accuracy: 0.9194\n",
            "Epoch 258/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2051 - accuracy: 0.9194\n",
            "Epoch 259/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1482 - accuracy: 0.9677\n",
            "Epoch 260/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1660 - accuracy: 0.9677\n",
            "Epoch 261/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1051 - accuracy: 0.9677\n",
            "Epoch 262/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1624 - accuracy: 0.9516\n",
            "Epoch 263/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1644 - accuracy: 0.9516\n",
            "Epoch 264/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1507 - accuracy: 0.9516\n",
            "Epoch 265/300\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1235 - accuracy: 0.9677\n",
            "Epoch 266/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1134 - accuracy: 0.9516\n",
            "Epoch 267/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1083 - accuracy: 0.9677\n",
            "Epoch 268/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1318 - accuracy: 0.9516\n",
            "Epoch 269/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1422 - accuracy: 0.9677\n",
            "Epoch 270/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1187 - accuracy: 0.9516\n",
            "Epoch 271/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1166 - accuracy: 0.9839\n",
            "Epoch 272/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1801 - accuracy: 0.9516\n",
            "Epoch 273/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2127 - accuracy: 0.9516\n",
            "Epoch 274/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1454 - accuracy: 0.9516\n",
            "Epoch 275/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1249 - accuracy: 0.9516\n",
            "Epoch 276/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1714 - accuracy: 0.9355\n",
            "Epoch 277/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1553 - accuracy: 0.9355\n",
            "Epoch 278/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1522 - accuracy: 0.9516\n",
            "Epoch 279/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1678 - accuracy: 0.9839\n",
            "Epoch 280/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1604 - accuracy: 0.9677\n",
            "Epoch 281/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1067 - accuracy: 0.9677\n",
            "Epoch 282/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1981 - accuracy: 0.9355\n",
            "Epoch 283/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2028 - accuracy: 0.9032\n",
            "Epoch 284/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1138 - accuracy: 0.9516\n",
            "Epoch 285/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1133 - accuracy: 0.9516\n",
            "Epoch 286/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1190 - accuracy: 0.9677\n",
            "Epoch 287/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1492 - accuracy: 0.9516\n",
            "Epoch 288/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1388 - accuracy: 0.9839\n",
            "Epoch 289/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1571 - accuracy: 0.9516\n",
            "Epoch 290/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1274 - accuracy: 0.9677\n",
            "Epoch 291/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.9516\n",
            "Epoch 292/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0992 - accuracy: 0.9839\n",
            "Epoch 293/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2346 - accuracy: 0.9194\n",
            "Epoch 294/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1144 - accuracy: 0.9516\n",
            "Epoch 295/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1474 - accuracy: 0.9516\n",
            "Epoch 296/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0900 - accuracy: 0.9677\n",
            "Epoch 297/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1621 - accuracy: 0.9677\n",
            "Epoch 298/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1102 - accuracy: 1.0000\n",
            "Epoch 299/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1339 - accuracy: 0.9516\n",
            "Epoch 300/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1057 - accuracy: 0.9839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "cj-129OnwEPA",
        "outputId": "c892a8fe-1519-4a46-e8f6-632089e4008a"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar lo necesario para poder re-utilizar este modelo en el futuro\n",
        "# el vocabulario utilizado (words)\n",
        "# las posibles clases\n",
        "# el modelo\n",
        "import pickle\n",
        "pickle.dump(words, open('words.pkl','wb'))\n",
        "pickle.dump(classes, open('classes.pkl','wb'))\n",
        "model.save('tu_bot_model.h5')"
      ],
      "metadata": {
        "id": "rpIRhbrZwHuA"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing y validación"
      ],
      "metadata": {
        "id": "vlpxzE9gwPM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convertir texto de entrada del usuario a tokens\n",
        "def text_to_tokens(text):\n",
        "    lemma_tokens = []\n",
        "    tokens = nlp(preprocess_clean_text(text.lower()))\n",
        "    for token in tokens:\n",
        "        lemma_tokens.append(token.lemma_)\n",
        "    #print(lemma_tokens)\n",
        "    return lemma_tokens\n",
        "\n",
        "# transformar el texto de entrada tokenizado a una representación OHE\n",
        "def bag_of_words(text, vocab): \n",
        "    tokens = text_to_tokens(text)\n",
        "    bow = [0] * len(vocab)\n",
        "    for w in tokens: \n",
        "        for idx, word in enumerate(vocab):\n",
        "            if word == w: \n",
        "                bow[idx] = 1\n",
        "    #print(bow)\n",
        "    return np.array(bow)\n",
        "\n",
        "# usar modelo con la entrada en OHE y los labels posibles (tags)\n",
        "def pred_class(text, vocab, labels): \n",
        "    bow = bag_of_words(text, vocab)\n",
        "    words_recognized = sum(bow)\n",
        "\n",
        "    return_list = []\n",
        "    if words_recognized > 0: # sólo si reconoció alguna palabra del vocabulario\n",
        "        result = model.predict(np.array([bow]))[0] # es un array de softmax\n",
        "        thresh = 0.2\n",
        "        # filtrar aquellas entradas menores al umbral `thresh`\n",
        "        y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
        "        # ordenar keys de acuerdo al valor softmax\n",
        "        y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "        # return_list es una lista de los labels de mayor a menor\n",
        "        for r in y_pred:\n",
        "            return_list.append(labels[r[0]])\n",
        "            #print(labels[r[0]], r[1])\n",
        "\n",
        "    # si no reconoció palabras del vocabulario se devuelve una lista vacía\n",
        "    return return_list\n",
        "\n",
        "# obtener una respuesta predeterminada \n",
        "def get_response(intents_list, intents_json):\n",
        "    tag = intents_list[0] # tomar el tag con el mejor valor softmax\n",
        "    list_of_intents = intents_json[\"intents\"] # intents_json es todo el dataset\n",
        "    for i in list_of_intents: \n",
        "        if i[\"tag\"] == tag: # buscar el tag correspoindiente y dar una respuesta predeterminada aleatoria \n",
        "            result = random.choice(i[\"responses\"])\n",
        "            break\n",
        "    return result"
      ],
      "metadata": {
        "id": "MWKoNQBewNIN"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    # pedir input al usuario\n",
        "    message = input(\"\")\n",
        "    print(\"Q:\", message)\n",
        "\n",
        "    intents = pred_class(message, words, classes)\n",
        "    if len(intents) > 0:\n",
        "        result = get_response(intents, dataset)\n",
        "        print(\"BOT:\", result)\n",
        "    else: # si no hubo ningún resultado que supere el umbral\n",
        "        print(\"BOT: Perdón, no comprendo la pregunta.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JEfg5npUwpQy",
        "outputId": "b30bf066-30f6-4846-98d9-29c42c35268a"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola!\n",
            "Q: Hola!\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "BOT: Hola, ¿Cómo estás?\n",
            "Todo bien, queria averiguar porque no me llego mi compra\n",
            "Q: Todo bien, queria averiguar porque no me llego mi compra\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "BOT: Podes ver los detalles de tu envio en el siguiente link <link> allí podrás iniciar un reclamo si el envío está demorado\n",
            "Gracias!\n",
            "Q: Gracias!\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "BOT: ¡Por nada!, cualquier otra consulta podes escribirme\n",
            "Como puedo saber si hay stock de un producto?\n",
            "Q: Como puedo saber si hay stock de un producto?\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "BOT: Si el producto se encuentra publicado, hay stock del mismo\n",
            "Tengo un problema con una compra\n",
            "Q: Tengo un problema con una compra\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "BOT: En el siguiente link podrás encontrar tus compras y los detalles de las mismas <link>\n",
            "Gracias\n",
            "Q: Gracias\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "BOT: ¡Por nada!, cualquier otra consulta podes escribirme\n",
            "Hacen envios a sucursales?\n",
            "Q: Hacen envios a sucursales?\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "BOT: Tenemos diferentes formas de envios según la zona, te recomiendo entrar a este <link>\n",
            "Quiero calificar un producto\n",
            "Q: Quiero calificar un producto\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "BOT: En el siguiente link podrás encontrar tus compras y calificar los productos <link>\n",
            "Quisiera saber cuales son los medios de pago\n",
            "Q: Quisiera saber cuales son los medios de pago\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "BOT: En el siguiente link podrás encontrar los beneficios y formas de pago vigentes\n",
            "Gracias!\n",
            "Q: Gracias!\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "BOT: ¡Por nada!, cualquier otra consulta podes escribirme\n",
            "Adios\n",
            "Q: Adios\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "BOT: Hasta luego!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-73fbfc2e4d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# pedir input al usuario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Q:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}